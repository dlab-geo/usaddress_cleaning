{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Street component of an address\n",
    "\n",
    "This script uses the python library **usaddress** to parse the street component of an address. The script does some minor preprocessing of the address before passing input to `usaddress`.  We have found these steps to improve geocoding results.\n",
    "\n",
    "- See: https://parserator.datamade.us/usaddress\n",
    "   \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import usaddress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big function to pre-clean an address and submit to `usaddress` parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1  # a global to keep track of number of addresses processed\n",
    "\n",
    "def get_clean_street(address, debug=0):\n",
    "    '''\n",
    "    Function to clean and tag street address component\n",
    "    Returns a clean street address component if the input type is Street Address\n",
    "    Else returns minimally cleaned version of the input.\n",
    "    '''\n",
    "    \n",
    "    cleaning_note = \"\"\n",
    "    \n",
    "    global counter\n",
    "    if debug == 1 :\n",
    "        print(str(counter)+\" input address: \" + address)\n",
    "    \n",
    "    #add some spaces where they are missing around odd chars\n",
    "    address =  re.sub('[.\\(){}<>\\']', ' ', address)\n",
    "    if debug == 1:\n",
    "        print(\"we now have: \" + address)\n",
    "                    \n",
    "        \n",
    "    # Dashes \n",
    "    # If number-number, remove dash\n",
    "    # else leave it or replace with a space\n",
    "    if re.search(r'^\\d+-\\d+\\s+', address):\n",
    "        # EG '49-866 AVE EL RIO' where 866 is the street name \n",
    "        address = re.sub('[.-]', '', address)\n",
    "        cleaning_note = \"Removed dash in num-dash-num|\"\n",
    "        if debug == 1:\n",
    "            print(\"we removed dash in num-dash-num and now have: \" + address)\n",
    "     \n",
    "    # Now if there is a dash still replace with a space\n",
    "    #'12-23rd st' or '#5-36 Main St'\n",
    "    if re.search(r'\\-', address):\n",
    "    \n",
    "        address =  re.sub('[.-]', ' ', address)\n",
    "        cleaning_note = cleaning_note + \"Removed dash in str|\"\n",
    "        \n",
    "        if debug ==1:\n",
    "            print(\"we removed a dash in string and now have: \" + address)\n",
    "        \n",
    "    # See if there is a forward slash in the address\n",
    "    # and make sure it has spaces around it\n",
    "    # if it is not a fraction\n",
    "    if not re.search(r' \\d+/\\d+', address):\n",
    "        if debug > 0:\n",
    "            print(\"no fraction so check and fix slashes\")\n",
    "        address = re.sub('[./]', ' ', address)\n",
    "    \n",
    "    #strip leading hastags\n",
    "    address = address.lstrip(\"#\")\n",
    "    \n",
    "    # strip leading spaces\n",
    "    address = address.lstrip()\n",
    "    \n",
    "    # replace multiple spaces with one space\n",
    "    address = re.sub('\\s+',' ', address ).strip()\n",
    "    \n",
    "    if debug == 1:\n",
    "        print(\"Pre-cleaned address: \", address)\n",
    "    \n",
    "    ############################################################\n",
    "    # Tagging address with usaddress\n",
    "    ############################################################\n",
    "    \n",
    "    try:\n",
    "        tagged_address, address_type = usaddress.tag(address)\n",
    "   \n",
    "        if debug == 2 :\n",
    "            print(tagged_address)\n",
    "\n",
    "        #addr_type = tagged_addr[1]\n",
    "        cleaning_note = cleaning_note + \"|usaddressType=\" + address_type\n",
    "            \n",
    "        if debug == 1:\n",
    "            print(\"Type of tagged addresss: \" + address_type)\n",
    "            \n",
    "        if (address_type == 'Street Address'):\n",
    "            y = tagged_address #tagged_addr[0]\n",
    "\n",
    "            paddr = \"\"\n",
    "            if 'AddressNumber' in y.keys():\n",
    "                paddr = (y['AddressNumber'])\n",
    "\n",
    "            if 'StreetNamePreType' in y.keys():\n",
    "                paddr = \" \".join([paddr, y['StreetNamePreType']])\n",
    "\n",
    "            if 'StreetNamePreDirectional' in y.keys():\n",
    "                paddr = \" \".join([paddr, y[\"StreetNamePreDirectional\"]])\n",
    "\n",
    "            if 'StreetName' in y.keys():\n",
    "                paddr = \" \".join([paddr, y[\"StreetName\"]])\n",
    "\n",
    "            if 'StreetNamePostDirectional' in y.keys():\n",
    "                paddr = \" \".join([paddr, y[\"StreetNamePostDirectional\"]])\n",
    "\n",
    "            if 'StreetNamePostType' in y.keys():\n",
    "                if y[\"StreetNamePostType\"].lower() in usaddress.STREET_NAMES:\n",
    "                    paddr = \" \".join([paddr, y[\"StreetNamePostType\"]])\n",
    "\n",
    "            if 'OccupancyIdentifier' in y.keys():\n",
    "                if debug == 1:\n",
    "                    print(\"we have an occupancy id\")\n",
    "                if not 'OccupancyType' in y.keys():\n",
    "                    if debug ==1:\n",
    "                        print(\"we do not have an occ type\")\n",
    "                    paddr = \" \".join([paddr, y['OccupancyIdentifier']])\n",
    "\n",
    "            if 'PlaceName' in y.keys():\n",
    "                paddr = \" \".join([paddr, y['PlaceName']])\n",
    "\n",
    "            if paddr == \"\":\n",
    "                paddr = address # set it back to original input\n",
    "                cleaning_note = \"|parsed usaddress.tag returned no string so resetting\"\n",
    "\n",
    "        else:\n",
    "            paddr = address\n",
    "            if debug == 1:\n",
    "                print(\"Returning pre-cleaned address: \" + paddr)\n",
    "            cleaning_note = cleaning_note + \"|returning pre-cleaned address\"\n",
    "    \n",
    "    except usaddress.RepeatedLabelError as e :\n",
    "        cleaning_note = cleaning_note + \"|usaddress.RepeatedLabelError so returning pre-cleaned address\"\n",
    "        paddr = address\n",
    "        \n",
    "    if debug > 0:\n",
    "        print(\"Cleaning note: \" + cleaning_note)\n",
    "    \n",
    "    counter = counter + 1\n",
    "   \n",
    "    return paddr, cleaning_note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal - clean up street component of the address\n",
    "* City,  state, and zip are usually fine\n",
    "* Any component that is known, eg all addresses are in the state of Calfornia, should manually set that value for all rows, eg:\n",
    "    * df['state'] = 'CA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data to be cleaned\n",
    "\n",
    "First identify one or more CSV files to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at our data to be processed - here in the indata directory\n",
    "!ls indata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify file(s) to be processed\n",
    "\n",
    "## One way to get a list of one or more files\n",
    "## UNCOMMENT to use this approach\n",
    "#my_files = !ls indata/*.csv\n",
    "#my_files\n",
    "\n",
    "## Or just identify the one file to be processed\n",
    "my_files = ['indata/sample_addresses2.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the file or files\n",
    "Chunk the file into separtate files of size **chunksize** if the data are larger than 100,000. You can increase this chunksize depending on your computer configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for infile in my_files:\n",
    "\n",
    "    print(\"Processing File: \", infile)\n",
    "    \n",
    "    chunksize = 100000 # max number of rows to process in case we have millions\n",
    "    file_counter = 0 # keep track of the number of files we output\n",
    "    \n",
    "    # Now read in the file in chunks\n",
    "    ## Note: you may need to change the column names \n",
    "    ## but you should specify the dtype for each\n",
    "    for df in pd.read_csv(infile, chunksize=chunksize, encoding=\"latin-1\", dtype={\"id\": str, \"address\": str, \"city\": str, 'zip': str, 'state': str}):\n",
    "        \n",
    "        file_counter = file_counter+1\n",
    "        print(\"\\nprocessing chunk: \" + str(file_counter))\n",
    "        \n",
    "        # Clean the addresses\n",
    "        df['clean_street'], df['clean_notes'] = zip(*df['street'].map(get_clean_street))\n",
    "        \n",
    "        # Sort the addresses - makes geocoding faster\n",
    "        df.sort_values(by=['city', 'zip'], inplace=True)\n",
    "        \n",
    "        # Check for and create output directory if needed\n",
    "        outdir = os.path.join(os.getcwd(),\"cleaned\")\n",
    "        if not os.path.isdir(outdir):\n",
    "            # If the output directory does not exist create it\n",
    "            !mkdir {outdir}\n",
    "            print('\\nOutput directory has been created:' + outdir)\n",
    "        else:\n",
    "            print(\"\\nOutput directory exists and is: \" + outdir)\n",
    "            \n",
    "        # Write cleaned addresses to csv file for geocoding\n",
    "        if infile.find(\"/\") >=0:\n",
    "            file_prefix = infile.split(\"/\")[1].split(\".\")[0]\n",
    "        else:\n",
    "            file_prefix =i[0:-4]\n",
    "    \n",
    "        outfile = outdir + \"/\"+ file_prefix +\"_cleaned_\" + str(file_counter) + \".csv\"\n",
    "        df.to_csv(outfile, index=False)\n",
    "        \n",
    "        print(\"Saving cleaned addresses to: \" + outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ouput\n",
    "!ls {outdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the output\n",
    "\n",
    "The **get_clean_street** function appends two columns to the output dataframe:\n",
    "\n",
    "- `clean_street` which has the cleaned address (single line format) \n",
    "- `clean_notes` any notes generated by the cleaning function.\n",
    "\n",
    "The only address data that is cleaned is the data contained in the column mapped to the function, e.g. **street** in the example shown below:\n",
    "\n",
    "> df['clean_street'], df['clean_notes'] = zip(*df['street'].map(get_clean_street))\n",
    "\n",
    "\n",
    "*Be sure to set the correct column to be cleaned - needs to match column label in your dataframe!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Created by Patty Frontiera, UC Berkeley\n",
    "Last updated Nov 11, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
